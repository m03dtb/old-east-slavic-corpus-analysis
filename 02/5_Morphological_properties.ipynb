{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92933f6-a9c1-412b-a64d-f77464a4c9ff",
   "metadata": {},
   "source": [
    "# File 02/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b3d753-19df-4379-9672-a18ece6e5102",
   "metadata": {},
   "source": [
    "## DESCRIPTION:\n",
    "- The file uses regex and other filter methods to extract prefixes\n",
    "- (e.g. < po- >) and suffixes (e.g. < -yva- >/< -iva- > or < -nuti >) of verbs \n",
    "### INPUTFILE:\n",
    "./OUTPUTS/dataframe_02_4.csv\n",
    "### OUTPUTFILE \n",
    "- ./OUTPUTS/dataframe_02_5.csv\n",
    "- ./VERBS_BY_TYPE/MAPPING_nu_from_NONE.csv\n",
    "- ./VERBS_BY_TYPE/MAPPING_NONE_is_sub_of_prefix.csv\n",
    "- ./VERBS_BY_TYPE/counts_VCOMB_*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45ca18f-5c36-496e-b1ee-b9c9213ce290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481862b9-5664-4af0-add1-80f32952f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read input file \n",
    "df = pd.read_csv(\"OUTPUTS/dataframe_02_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3966b60d-8fa1-48f3-ad90-c1c156669ea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop_unnamed_columns\u001b[39m(df):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# keep only columns not starting with \"Unnamed..\"\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df.loc[:, ~df.columns.str.startswith(\u001b[33m\"\u001b[39m\u001b[33mUnnamed\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = drop_unnamed_columns(\u001b[43mdf\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def drop_unnamed_columns(df):\n",
    "    # keep only columns not starting with \"Unnamed..\"\n",
    "    return df.loc[:, ~df.columns.str.startswith(\"Unnamed\")]\n",
    "\n",
    "df = drop_unnamed_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b9fbe1-c46d-47ec-b58a-5b0d0a3835ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['File', 'Text Title', 'Language', 'Sentence ID', 'Token ID', 'Form',\n",
       "       'Lemma', 'Lemma_norm', 'POS', 'Morphology', 'Head ID', 'Relation',\n",
       "       'Presentation After', 'Russian Translation', 'English Translation',\n",
       "       'Type', 'century', 'exact', 'lang', 'region', 'Negation',\n",
       "       'Negation_Marker', 'place', 'Sentence_Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd049003-96d0-4f80-a2d3-bdc6d68ef884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-' 'Pp' 'Ne' 'A-' 'Nb' 'V-' 'R-' 'Pt' 'C-' 'G-' 'Px' 'Ps' 'Pd' nan 'Pk'\n",
      " 'Df' 'Mo' 'Ma' 'Dq' 'Pr' 'Du' 'Pi' 'Pc' 'F-']\n"
     ]
    }
   ],
   "source": [
    "print(df.POS.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e74f4-e64c-4f75-861c-e0352dca8cf2",
   "metadata": {},
   "source": [
    "### From now on: use \"Lemma_norm\" instead of \"Lemma\" \n",
    "### -> INFO:  \"Lemma_norm\" is the normalized variant of \"Lemma\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f828fb-1152-4c0b-9c01-56ead747a796",
   "metadata": {},
   "source": [
    "# A) Get the set of all verbs in \"Lemma_norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8bf90d9-ff1c-4d93-b678-493fff4ee6e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m##################################################################\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# P01) \u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# SET OF Lemma_norm (i.e.  POS=\"V-\") \u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m##################################################################\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1) List of Verbs, i.e. \"POS\" == \"V-\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m mask = \u001b[43mdf\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mPOS\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mV-\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2) get base_form column\u001b[39;00m\n\u001b[32m     10\u001b[39m base_forms_norm = df.loc[mask, \u001b[33m\"\u001b[39m\u001b[33mLemma_norm\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "# P01) \n",
    "# SET OF Lemma_norm (i.e.  POS=\"V-\") \n",
    "##################################################################\n",
    "\n",
    "# 1) List of Verbs, i.e. \"POS\" == \"V-\"\n",
    "mask = df[\"POS\"] == \"V-\"\n",
    "\n",
    "# 2) get base_form column\n",
    "base_forms_norm = df.loc[mask, \"Lemma_norm\"]\n",
    "\n",
    "# 3) List of base_forms_norm \n",
    "base_forms_norm_list_all = base_forms_norm.tolist()\n",
    "\n",
    "# 4) get list of uniq Lemma_norm entries\n",
    "base_forms_norm_list_set = set(base_forms_norm_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f69b9c-7804-474d-8e91-b66dcb16603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma_Norm:\n",
      "\n",
      "['д_ржати', 'повелети', 'быти', 'от_дати', 'почати', 'хотети', 'от_яти', 'быти', 'от_имати', 'с_стояти']\n",
      "<class 'list'>\n",
      "\n",
      "Sum of entries 'Lemma_norm': 42652\n",
      "\n",
      "Unique forms of 'Lemma_norm' (=SET): 3778\n",
      "\n",
      "First 20 entries:\n",
      "['уимати', 'обестити', 'приложити', 'урод_ствовати', 'об_говаривати', 'перекыдати', 'высягнути', 'прив_метати', 'от_врещи', 'наести', 'обламывати', 'пополаскывати', 'перекрепливати', 'нагрязнити', 'преложити', 'поругати', 'с_судити', 'с_бродити', 'в_ст_ргнути', 'с_грести', 'даровати']\n"
     ]
    }
   ],
   "source": [
    "print(\"Lemma_Norm:\\n\")\n",
    "print(base_forms_norm_list_all[:10])\n",
    "print(type(base_forms_norm_list_all))\n",
    "verbs_altogether = len(base_forms_norm_list_all)\n",
    "print(f\"\\nSum of entries 'Lemma_norm': {verbs_altogether}\")\n",
    "\n",
    "set_verbs_num = set(base_forms_norm_list_all)\n",
    "print(f\"\\nUnique forms of 'Lemma_norm' (=SET): {len(set_verbs_num)}\")\n",
    "verb_list = list(set_verbs_num)\n",
    "print(f\"\\nFirst 20 entries:\\n{verb_list[:21]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13081c28-8c78-404b-bf84-417d67352202",
   "metadata": {},
   "source": [
    "# Which derivatives can presumably be found by deriving from simplex?\n",
    "- D: читати -> simplex\n",
    " - -> I: читывати -> iteratives \n",
    " - -> P: прочитати -> perfective form of simplex \n",
    "- P: прочитати -> perfective form of simplex \n",
    " - -> PI: прочитывати -> secondary imperfectives  \n",
    " - -> PS: распрочитати -> double prefixed perfective form \n",
    "- PS: распрочитати -> double prefixed perfective form \n",
    " - -> PSI: распрочитывати -> secondary imperfective with double prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0be3f6-95bf-48b2-87d3-4a96a57f7a9b",
   "metadata": {},
   "source": [
    "# Create columns storing info about \n",
    "## - secondary imperfective verbs: {-yvati} / {-ivati} -> Output: Boolean (True/False) in Spalte \"V_yva\"\n",
    "## - prefixed verb ->  Output: Boolean (True/False) in Spalte \"V_prefix\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795e0a8-dbbd-41e9-bd90-142a3349da55",
   "metadata": {},
   "source": [
    "# A) I. Implement col \"V_yya\": \n",
    "## val == True, if verb contains suffix {-yva} or variant {-iva}; else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51ac533d-54e0-4473-a2fe-8192fb675eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_v_yva_column(\n",
    "    df: pd.DataFrame,\n",
    "    anchor: str = \"Lemma_norm\",\n",
    "    new_col: str = \"V_yva\",\n",
    "    suffixes: Tuple[str, ...] = (\"ивати\", \"ывати\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create column V_yva and assign Boolean True if valid suffix, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # 0) Show columns before modification (debugging / sanity check)\n",
    "    df_cols_before = set(df.columns.tolist())\n",
    "\n",
    "    # 1) Build mask: lemma ends with one of the suffixes\n",
    "    mask = df[anchor].str.endswith(suffixes, na=False)\n",
    "\n",
    "    # 2) Check if column already exists\n",
    "    if new_col in df.columns:\n",
    "        print(\"Column already exists\")\n",
    "        return df\n",
    "\n",
    "    # 3) Insert column after anchor if possible\n",
    "    if anchor in df.columns:\n",
    "        insert_pos = df.columns.get_loc(anchor) + 1\n",
    "        df.insert(insert_pos, new_col, mask)\n",
    "    else:\n",
    "        print(f\"Column '{anchor}' not found – appending '{new_col}' at the end.\")\n",
    "        df[new_col] = mask\n",
    "\n",
    "    # 4) Show newly added columns\n",
    "    df_cols_after = set(df.columns.tolist())\n",
    "    print(f\"Newly created col: {df_cols_after - df_cols_before}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fbfd460-b0af-42e0-a755-18aef914c520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newly created col: {'V_yva'}\n"
     ]
    }
   ],
   "source": [
    "# df ist dein bestehendes DataFrame\n",
    "df = add_v_yva_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad0b21-a501-4be9-a480-ee9c5d1b34fa",
   "metadata": {},
   "source": [
    "# A) II a. To find prefixed verbs, i.e. in order to populate col \"V_prefix\":\n",
    "## Implemen base_prefixes as regex variants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d32f33-626c-4ab7-9bcb-cb89fa017458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considers all prefixes mentioned in Zanchi & Naccarato (2016, 368) \n",
    "# as well as all prefixes known in Modern Standard Russian (MSR)\n",
    "base_prefixes = [\n",
    "    'без', 'вз', 'воз', 'вос', 'вс', 'въ', 'вы', 'до', 'за', 'из', 'изо',\n",
    "    'ис', 'на', 'над', 'надо', 'о', 'об', 'обо', 'от', 'ото', 'пере', 'по',\n",
    "    'под', 'подо', 'пре', 'пред', 'предо', 'при', 'про', 'прѣ',\n",
    "    'раз', 'разо', 'рас', 'роз', 'рос', 'с', 'со', 'у', 'через'\n",
    "]\n",
    "\n",
    "# base_prefixes may have different graphemic variants in Old East Slavic \n",
    "variants = {\n",
    "    \"без\":   r\"бе[зѕс]ь?\",\n",
    "    \"в\":     r\"в[ъьо]?\",\n",
    "    \"вз\":    r\"в[ъьо][зс]?\",\n",
    "    \"из\":    r\"и[зсѕ]ь?\",\n",
    "    \"раз\":   r\"р[ао][зсѕ]ъ?\",\n",
    "    \"с\":     r\"с[ъьо]?\",\n",
    "    \"воз\":   r\"в[ъьо][сз]\",\n",
    "    \"над\":   r\"над[ъьо]?\",\n",
    "    \"об\":    r\"об[ъьо]?\",\n",
    "    \"от\":    r\"от[ъьо]?\",\n",
    "    \"через\": r\"чере[зс][ъьо]?\",\n",
    "}\n",
    "\n",
    "# ---------- 1) build combined regex ----------\n",
    "def build_combined_regex(bases, special):\n",
    "    patterns = [\n",
    "        special.get(p, re.escape(p))    # fallback = prefix itself\n",
    "        # longest prefix first > so that e.g. {pred-} is found before {pre-} etc.\n",
    "        # to guarantee that the correct prefix is found \n",
    "        for p in sorted(bases, key=len, reverse=True)  \n",
    "    ]\n",
    "    return r'^(' + '|'.join(patterns) + ')'\n",
    "\n",
    "combined_regex = build_combined_regex(base_prefixes, variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131080b-0569-4157-a18c-bd06e172f996",
   "metadata": {},
   "source": [
    "# A) II b. Implement col \"V_prefix\" -> Value: Boolean (True/False) \n",
    "## True: if verb is prefixed, else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1047d5cf-d365-4516-b410-2c5f77bc31dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_V_prefix_column(df: pd.DataFrame, combined_regex: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create col 'V_prefix',\n",
    "    which is True for (POS=='V-') if one of the prefix patterns is found in col 'Lemma'.\n",
    "    Insert col 'V_prefix' to the right of col 'V_yva'. \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # 1) Initialize \"V_prefix\" with value False\n",
    "    df['V_prefix'] = False\n",
    "\n",
    "    # 2) Mask for verbs only (i.e. POS == \"V-\")\n",
    "    mask_verbs = df['POS'] == 'V-'\n",
    "    # Mask for regex match only \n",
    "    mask_prefix = df['Lemma'].astype(str).str.contains(combined_regex, regex=True, na=False)\n",
    "    # set True in col 'V_prefix' if condition of both masks is True\n",
    "    df.loc[mask_verbs & mask_prefix, 'V_prefix'] = True\n",
    "\n",
    "    # 3) adjust column order: insert 'V_prefix' right to col 'V_yva'\n",
    "    cols = list(df.columns)\n",
    "    if 'V_yva' in cols:\n",
    "        idx = cols.index('V_yva')\n",
    "        cols.remove('V_prefix')\n",
    "        cols.insert(idx + 1, 'V_prefix')\n",
    "        df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "280987aa-7b13-40ea-860f-0eddb0de08cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/86qydyw53xj72p_g1g25hfx00000gn/T/ipykernel_61069/2213503322.py:14: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask_prefix = df['Lemma'].astype(str).str.contains(combined_regex, regex=True, na=False)\n"
     ]
    }
   ],
   "source": [
    "df = add_V_prefix_column(df, combined_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7305be3-0674-45d0-9312-149d8a08ccb3",
   "metadata": {},
   "source": [
    "# A) III. Implement col \"V_nuti\" -> Value: Boolean (True/False)\n",
    "## True: if verb ends in {-nuti}, else False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ef4429-52d8-433c-ab0a-f00db5f6c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_V_nuti_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create col 'V_nuti'. \n",
    "    For all (POS=='V-'): if 'Lemma_norm' ends in {-нути} ({-nuti}), 'V_yva' is True, else False. \n",
    "    Insert col right next to 'V_yva'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame)\n",
    "    Returns:\n",
    "        pd.DataFrame: with col 'V_nuti' \n",
    "    \"\"\"\n",
    "    # 1) filter for verbs only \n",
    "    df_verbs = df[df[\"POS\"] == \"V-\"]\n",
    "\n",
    "    # 2) build mask: Lemma_norm ends in \"нуть\"\n",
    "    mask_nuti = df_verbs[\"Lemma_norm\"].str.endswith(\"нути\", na=False)\n",
    "\n",
    "    # 3) Create new col for Boolean for all cols \n",
    "    # (not only cols containing verbs, i.e. \"POS\"==\"V-\")\n",
    "    #  Defautlt: set all values to \"False\"\n",
    "    df[\"V_nuti\"] = False\n",
    "    # reset those to True if Verb ends in {-nuti}\n",
    "    df.loc[df_verbs.index[mask_nuti], \"V_nuti\"] = True\n",
    "\n",
    "    # 4) Adjust col order: find index of col 'V_yva'\n",
    "    cols = list(df.columns)\n",
    "    if \"V_yva\" in cols:\n",
    "        idx_v_yva = cols.index(\"V_yva\")\n",
    "        # del col 'V_nuti' (as it is at the end of df right now)\n",
    "        cols.remove(\"V_nuti\")\n",
    "        # Insert 'V_nuti' right after 'V_yva'\n",
    "        cols.insert(idx_v_yva + 1, \"V_nuti\")\n",
    "        # Return DataFrame with new col order \n",
    "        return df[cols]\n",
    "    else:\n",
    "        # If no 'V_yva' in DF, 'V_nuti' stays at the end of the df \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f180f6d0-2e54-4ce7-9812-cd27c15be86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= add_V_nuti_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656ec72-3f26-4e4a-8f84-0b7b7c77f022",
   "metadata": {},
   "source": [
    "# B) Print combinations of \"V_yva\", \"V_prefix\", \"V_nuti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0570423b-2f95-40a4-9572-898a59ebf4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: (Form: (verb form count, lemma count))\n",
      "Only yva:\t\t (132, 10)\n",
      "Only prefix:\t\t (23947, 2844)\n",
      "Only nuti:\t\t (120, 38)\n",
      "prefix ∧ yva:\t\t (471, 152)\n",
      "yva ∧ nuti:\t\t (0, 0)\n",
      "prefix ∧ nuti:\t\t (664, 157)\n",
      "prefix ∧ yva ∧ nuti:\t (0, 0)\n",
      "\n",
      "Sum of verbs for which one of the above conditions is true: 25334\n",
      "All verbs: 42652\n"
     ]
    }
   ],
   "source": [
    "# 1) Define masks \n",
    "mask_v   = df[\"POS\"]==\"V-\"\n",
    "mask_yva = df.get(\"V_yva\", False)==True\n",
    "mask_pre = df.get(\"V_prefix\", False)==True\n",
    "mask_nut = df.get(\"V_nuti\", False)==True\n",
    "\n",
    "# 2) Exclusive Masks\n",
    "only_yva       = mask_v & mask_yva & ~mask_pre & ~mask_nut\n",
    "only_prefix    = mask_v & mask_pre & ~mask_yva & ~mask_nut\n",
    "only_nuti      = mask_v & mask_nut & ~mask_yva & ~mask_pre\n",
    "\n",
    "yva_and_pref   = mask_v & mask_yva & mask_pre & ~mask_nut\n",
    "yva_and_nuti   = mask_v & mask_yva & mask_nut & ~mask_pre\n",
    "pref_and_nuti  = mask_v & mask_pre & mask_nut & ~mask_yva\n",
    "\n",
    "all_three      = mask_v & mask_yva & mask_pre & mask_nut\n",
    "\n",
    "# 3) Count\n",
    "def cnt(m):\n",
    "    sub = df[m]\n",
    "    return len(sub), sub[\"Lemma_norm\"].nunique()\n",
    "\n",
    "\n",
    "print(\"Entities: (Form: (verb form count, lemma count))\")\n",
    "print(\"Only yva:\\t\\t\",       cnt(only_yva))\n",
    "print(\"Only prefix:\\t\\t\",    cnt(only_prefix))\n",
    "print(\"Only nuti:\\t\\t\",      cnt(only_nuti))\n",
    "print(\"prefix ∧ yva:\\t\\t\",  cnt(yva_and_pref))\n",
    "print(\"yva ∧ nuti:\\t\\t\",    cnt(yva_and_nuti))\n",
    "print(\"prefix ∧ nuti:\\t\\t\", cnt(pref_and_nuti))\n",
    "print(\"prefix ∧ yva ∧ nuti:\\t\",     cnt(all_three))\n",
    "\n",
    "# 4) Summen\n",
    "total_exclusive = sum(cnt(m)[0] for m in [only_yva,only_prefix,only_nuti,\n",
    "                                         yva_and_pref,yva_and_nuti,\n",
    "                                         pref_and_nuti,all_three])\n",
    "print()\n",
    "print(\"Sum of verbs for which one of the above conditions is true:\", total_exclusive)\n",
    "print(\"All verbs:\", len(df[mask_v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819bf59-eb04-4dd8-8ac7-cd9a73911d31",
   "metadata": {},
   "source": [
    "# Create a separate col where all above masks are summed up to one unique property "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4954919b-aa17-4474-89b1-2ba8fe64ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_V_COMB_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a column \"V_COMB\" according to the logic below: \n",
    "      - POS != \"V-\" → \"0\"\n",
    "      - POS == \"V-\" & no Flags True  → \"1\"\n",
    "      - if entry is not a verb: df[\"V_COMB\"] == 0\n",
    "      - if entry is Verb and has none of the above = NONE \n",
    "      - other output in \"V_COMB\": \n",
    "        pref, pref_nu, pref_yva, yva, nu \n",
    "\n",
    "    - Insert Column right to \"V_nuti\" if the latter exists, else to the end of the df columns \n",
    "    - Important: Values can never overwrite each other, i.e. \n",
    "    \"pref_nu\" cannot be overwritten by \"pref\" or vice versa\n",
    "    \"\"\"\n",
    "    def make_comb(row):\n",
    "        # 1) If entry is not a verb: \n",
    "        if row.get(\"POS\") != \"V-\":\n",
    "            return \"0\"\n",
    "        \n",
    "        # 2) Collect all flags set in order: YVA (2), PREFIX (3), NUTI (4)\n",
    "        comb = \"\"\n",
    "        if row.get(\"V_prefix\", False):\n",
    "            comb += \"_pref\"\n",
    "        if row.get(\"V_yva\", False):\n",
    "            comb += \"_yva\"\n",
    "        if row.get(\"V_nuti\", False):\n",
    "            comb += \"_nu\"\n",
    "        \n",
    "        # 3) if none of the 3 flags is True, return \"1\"\n",
    "        return comb[1:] if comb else \"NONE\"\n",
    "    \n",
    "    # Create new column \"V_COMB\":\n",
    "    df[\"V_COMB\"] = df.apply(make_comb, axis=1)\n",
    "    \n",
    "    # Adjust col order:  set col \"V_COMB\" on the right to col \"V_nuti\"\n",
    "    cols = list(df.columns)\n",
    "    if \"V_nuti\" in cols:\n",
    "        idx_nuti = cols.index(\"V_nuti\")\n",
    "        cols.remove(\"V_COMB\")         # V_COMB at the very right \n",
    "        cols.insert(idx_nuti + 1, \"V_COMB\")\n",
    "        return df[cols]\n",
    "    else:\n",
    "        # If V_nuti not existent then V_COMB stays at the very right\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15e67b97-c5bd-4578-9f27-c0d278db7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_V_COMB_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e62d3269-fd17-4e7a-b0d4-7c22943807e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_count = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b804a4-fcb3-450a-9118-05659e46f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of cols in df:  28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Text Title</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentence ID</th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Form</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Lemma_norm</th>\n",
       "      <th>V_yva</th>\n",
       "      <th>V_nuti</th>\n",
       "      <th>V_COMB</th>\n",
       "      <th>V_prefix</th>\n",
       "      <th>POS</th>\n",
       "      <th>Morphology</th>\n",
       "      <th>Head ID</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Presentation After</th>\n",
       "      <th>Russian Translation</th>\n",
       "      <th>English Translation</th>\n",
       "      <th>Type</th>\n",
       "      <th>century</th>\n",
       "      <th>exact</th>\n",
       "      <th>lang</th>\n",
       "      <th>region</th>\n",
       "      <th>Negation</th>\n",
       "      <th>Negation_Marker</th>\n",
       "      <th>place</th>\n",
       "      <th>Sentence_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157773</td>\n",
       "      <td>Се</td>\n",
       "      <td>се</td>\n",
       "      <td>се</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>I-</td>\n",
       "      <td>---------n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>voc</td>\n",
       "      <td></td>\n",
       "      <td>вот, это</td>\n",
       "      <td>behold, here is</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157774</td>\n",
       "      <td>азъ</td>\n",
       "      <td>азъ</td>\n",
       "      <td>аз_</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Pp</td>\n",
       "      <td>1s---mn--i</td>\n",
       "      <td>2157784.0</td>\n",
       "      <td>sub</td>\n",
       "      <td></td>\n",
       "      <td>я</td>\n",
       "      <td>I</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157775</td>\n",
       "      <td>мьстиславъ</td>\n",
       "      <td>мьстиславъ</td>\n",
       "      <td>м_стислав_</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Ne</td>\n",
       "      <td>-s---mn--i</td>\n",
       "      <td>2157774.0</td>\n",
       "      <td>apos</td>\n",
       "      <td></td>\n",
       "      <td>Мстислав</td>\n",
       "      <td>Mstislav</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157776</td>\n",
       "      <td>володимирь</td>\n",
       "      <td>володимирь</td>\n",
       "      <td>володимир_</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>A-</td>\n",
       "      <td>-s---mnpsi</td>\n",
       "      <td>2157777.0</td>\n",
       "      <td>atr</td>\n",
       "      <td></td>\n",
       "      <td>Владимира</td>\n",
       "      <td>Vladimir's</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157777</td>\n",
       "      <td>сн҃ъ</td>\n",
       "      <td>сынъ</td>\n",
       "      <td>сын_</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Nb</td>\n",
       "      <td>-s---mn--i</td>\n",
       "      <td>2157775.0</td>\n",
       "      <td>apos</td>\n",
       "      <td></td>\n",
       "      <td>сын</td>\n",
       "      <td>son</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157778</td>\n",
       "      <td>дьржа</td>\n",
       "      <td>дьржати</td>\n",
       "      <td>д_ржати</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "      <td>V-</td>\n",
       "      <td>-sppamn-si</td>\n",
       "      <td>2157784.0</td>\n",
       "      <td>xadv</td>\n",
       "      <td></td>\n",
       "      <td>держать, задерживать, иметь, блюсти, возвр:дер...</td>\n",
       "      <td>hold, possess, keep, refl:keep</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157779</td>\n",
       "      <td>рѹськѹ</td>\n",
       "      <td>русьскыи</td>\n",
       "      <td>рус_скыи</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>A-</td>\n",
       "      <td>-s---fapsi</td>\n",
       "      <td>2157780.0</td>\n",
       "      <td>atr</td>\n",
       "      <td></td>\n",
       "      <td>русский</td>\n",
       "      <td>Rusian</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157780</td>\n",
       "      <td>землю</td>\n",
       "      <td>земля</td>\n",
       "      <td>земля</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Nb</td>\n",
       "      <td>-s---fa--i</td>\n",
       "      <td>2157778.0</td>\n",
       "      <td>obj</td>\n",
       "      <td></td>\n",
       "      <td>земля</td>\n",
       "      <td>land, soil, ground</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157781</td>\n",
       "      <td>въ</td>\n",
       "      <td>въ</td>\n",
       "      <td>в_</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>R-</td>\n",
       "      <td>---------n</td>\n",
       "      <td>2157778.0</td>\n",
       "      <td>adv</td>\n",
       "      <td></td>\n",
       "      <td>в, на, за</td>\n",
       "      <td>in, into, on, at, for</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mst</td>\n",
       "      <td>Mstislav’s letter</td>\n",
       "      <td>orv</td>\n",
       "      <td>189407</td>\n",
       "      <td>2157782</td>\n",
       "      <td>своѥ</td>\n",
       "      <td>свои</td>\n",
       "      <td>свои</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Pt</td>\n",
       "      <td>3s---na--i</td>\n",
       "      <td>2157783.0</td>\n",
       "      <td>atr</td>\n",
       "      <td></td>\n",
       "      <td>свой</td>\n",
       "      <td>self’s, own</td>\n",
       "      <td>OR</td>\n",
       "      <td>12</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>East Slavic</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File         Text Title Language  Sentence ID  Token ID        Form  \\\n",
       "0  mst  Mstislav’s letter      orv       189407   2157773          Се   \n",
       "1  mst  Mstislav’s letter      orv       189407   2157774         азъ   \n",
       "2  mst  Mstislav’s letter      orv       189407   2157775  мьстиславъ   \n",
       "3  mst  Mstislav’s letter      orv       189407   2157776  володимирь   \n",
       "4  mst  Mstislav’s letter      orv       189407   2157777        сн҃ъ   \n",
       "5  mst  Mstislav’s letter      orv       189407   2157778       дьржа   \n",
       "6  mst  Mstislav’s letter      orv       189407   2157779      рѹськѹ   \n",
       "7  mst  Mstislav’s letter      orv       189407   2157780       землю   \n",
       "8  mst  Mstislav’s letter      orv       189407   2157781          въ   \n",
       "9  mst  Mstislav’s letter      orv       189407   2157782        своѥ   \n",
       "\n",
       "        Lemma  Lemma_norm  V_yva  V_nuti V_COMB  V_prefix POS  Morphology  \\\n",
       "0          се          се  False   False      0     False  I-  ---------n   \n",
       "1         азъ         аз_  False   False      0     False  Pp  1s---mn--i   \n",
       "2  мьстиславъ  м_стислав_  False   False      0     False  Ne  -s---mn--i   \n",
       "3  володимирь  володимир_  False   False      0     False  A-  -s---mnpsi   \n",
       "4        сынъ        сын_  False   False      0     False  Nb  -s---mn--i   \n",
       "5     дьржати     д_ржати  False   False   NONE     False  V-  -sppamn-si   \n",
       "6    русьскыи    рус_скыи  False   False      0     False  A-  -s---fapsi   \n",
       "7       земля       земля  False   False      0     False  Nb  -s---fa--i   \n",
       "8          въ          в_  False   False      0     False  R-  ---------n   \n",
       "9        свои        свои  False   False      0     False  Pt  3s---na--i   \n",
       "\n",
       "     Head ID Relation Presentation After  \\\n",
       "0        NaN      voc                      \n",
       "1  2157784.0      sub                      \n",
       "2  2157774.0     apos                      \n",
       "3  2157777.0      atr                      \n",
       "4  2157775.0     apos                      \n",
       "5  2157784.0     xadv                      \n",
       "6  2157780.0      atr                      \n",
       "7  2157778.0      obj                      \n",
       "8  2157778.0      adv                      \n",
       "9  2157783.0      atr                      \n",
       "\n",
       "                                 Russian Translation  \\\n",
       "0                                           вот, это   \n",
       "1                                                  я   \n",
       "2                                           Мстислав   \n",
       "3                                          Владимира   \n",
       "4                                                сын   \n",
       "5  держать, задерживать, иметь, блюсти, возвр:дер...   \n",
       "6                                            русский   \n",
       "7                                              земля   \n",
       "8                                          в, на, за   \n",
       "9                                               свой   \n",
       "\n",
       "              English Translation Type  century   exact lang       region  \\\n",
       "0                 behold, here is   OR       12  1130.0   OR  East Slavic   \n",
       "1                               I   OR       12  1130.0   OR  East Slavic   \n",
       "2                        Mstislav   OR       12  1130.0   OR  East Slavic   \n",
       "3                      Vladimir's   OR       12  1130.0   OR  East Slavic   \n",
       "4                             son   OR       12  1130.0   OR  East Slavic   \n",
       "5  hold, possess, keep, refl:keep   OR       12  1130.0   OR  East Slavic   \n",
       "6                          Rusian   OR       12  1130.0   OR  East Slavic   \n",
       "7              land, soil, ground   OR       12  1130.0   OR  East Slavic   \n",
       "8           in, into, on, at, for   OR       12  1130.0   OR  East Slavic   \n",
       "9                     self’s, own   OR       12  1130.0   OR  East Slavic   \n",
       "\n",
       "   Negation Negation_Marker     place  \\\n",
       "0     False             NaN  Novgorod   \n",
       "1     False             NaN  Novgorod   \n",
       "2     False             NaN  Novgorod   \n",
       "3     False             NaN  Novgorod   \n",
       "4     False             NaN  Novgorod   \n",
       "5     False             NaN  Novgorod   \n",
       "6     False             NaN  Novgorod   \n",
       "7     False             NaN  Novgorod   \n",
       "8     False             NaN  Novgorod   \n",
       "9     False             NaN  Novgorod   \n",
       "\n",
       "                                    Sentence_Text  \n",
       "0  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "1  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "2  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "3  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "4  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "5  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "6  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "7  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "8  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  \n",
       "9  азъ ѥсмь повелѣлъ ѿдати бѹицѣ (и (съ, съ, съ))  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',column_count)\n",
    "pd.set_option('display.max_rows',100)\n",
    "print(f\"num of cols in df: \", column_count)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a48e07-95b4-4199-bddf-d9ec3c66323c",
   "metadata": {},
   "source": [
    "# How many unique tokens exist (might be of the same type, here: Lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b6c3485-f363-429d-a8ab-2da91ad7b4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V_COMB\n",
       "0           192623\n",
       "pref         23947\n",
       "NONE         17318\n",
       "pref_nu        664\n",
       "pref_yva       471\n",
       "yva            132\n",
       "nu             120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.V_COMB.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11f39388-42e3-46e6-88e0-b75f18cc3bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(235275)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.V_COMB.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44050549-a0db-44f4-9870-3551d9b2d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"OUTPUTS/dataframe_02_5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f572380-420e-4163-8d96-0d1ca3ca19a2",
   "metadata": {},
   "source": [
    "# For each combination: get the according lemmas (\"Lemma_norm\") and count \n",
    "# their occurrences\n",
    "## Reference:\n",
    "df[\"Lemma_norm\"], df[\"V_COMB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c766634-e823-4b6c-b4b0-3af4943e5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_counts_by_vcomb(df: pd.DataFrame) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Get all unique values from V_COMB, \n",
    "\n",
    "    Return a nested dictionary of the form:\n",
    "    {\n",
    "        V_COMB_value: {\n",
    "            Lemma_norm: frequency,\n",
    "            ...\n",
    "        },\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    return {\n",
    "        comb: subdf[\"Lemma_norm\"].value_counts().to_dict()\n",
    "        for comb, subdf in df.groupby(\"V_COMB\")\n",
    "    }\n",
    "\n",
    "# call function\n",
    "counts = lemma_counts_by_vcomb(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f40bdb-f004-4878-bbf5-4069db0b2e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NONE: [('быти', 4817), ('рещи', 1131), ('ити', 754), ('глаголати', 573), ('хотети', 556), ('видети', 452), ('дати', 436), ('имети', 356), ('творити', 281), ('бити', 265)]\n",
      "\n",
      "nu: [('минути', 24), ('д_рзнути', 15), ('кликнути', 13), ('кынути', 10), ('т_лкнути', 5), ('тонути', 4), ('коснути', 3), ('тянути', 3), ('треснути', 3), ('тронути', 3)]\n",
      "\n",
      "pref: [('приити', 887), ('с_творити', 495), ('пос_лати', 491), ('поити', 463), ('в_зяти', 436), ('начати', 356), ('стати', 295), ('слышати', 280), ('прияти', 262), ('стояти', 228)]\n",
      "\n",
      "pref_nu: [('побегнути', 73), ('погыбнути', 55), ('помянути', 34), ('прибегнути', 26), ('в_здвигнути', 24), ('ужаснути', 17), ('покынути', 16), ('ус_нути', 16), ('в_зд_хнути', 15), ('постигнути', 15)]\n",
      "\n",
      "pref_yva: [('пребывати', 67), ('призывати', 34), ('наказывати', 34), ('с_казывати', 28), ('с_прашивати', 17), ('забывати', 15), ('убивати', 12), ('почивати', 11), ('избивати', 10), ('проливати', 8)]\n",
      "\n",
      "yva: [('бывати', 122), ('давывати', 2), ('живати', 1), ('пуживати', 1), ('прашивати', 1), ('пивати', 1), ('клачивати', 1), ('бранивати', 1), ('купливати', 1), ('говаривати', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get list of unique V_COMB values \n",
    "vcomb_list = df[\"V_COMB\"].unique().tolist()\n",
    "\n",
    "# print first ten values per key to console: \n",
    "for v in sorted(vcomb_list):\n",
    "    if v != \"0\":\n",
    "        top10 = list(counts.get(v, {}).items())[:10]\n",
    "        print(f\"{v}: {top10}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd31924a-bfbb-4b76-a0c4-6f7f81c0a001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all counts in all groups V_COMBI: 229_155\n",
      "Sum of unique Lemma_norm: 12_768\n"
     ]
    }
   ],
   "source": [
    "# 1. Sum of all counts\n",
    "total_counts = sum(\n",
    "    freq\n",
    "    for subdict in counts.values()\n",
    "    for freq in subdict.values()\n",
    ")\n",
    "\n",
    "# 2. Number of unique lemmas over all groups \n",
    "unique_lemmas = {\n",
    "    lemma\n",
    "    for subdict in counts.values()\n",
    "    for lemma in subdict.keys()\n",
    "}\n",
    "num_unique_lemmas = len(unique_lemmas)\n",
    "\n",
    "print(f\"Sum of all counts in all groups V_COMBI: {total_counts:_}\")\n",
    "print(f\"Sum of unique Lemma_norm: {num_unique_lemmas:_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a533d-e950-44cf-92e4-e5cfbdf35eea",
   "metadata": {},
   "source": [
    "## For each combination: write the verbs and frequencies to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab687ca2-6911-4bfc-b819-8ae27c3ee26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file: VERBS_BY_TYPE/counts_VCOMB_NONE.csv\n",
      "Wrote file: VERBS_BY_TYPE/counts_VCOMB_nu.csv\n",
      "Wrote file: VERBS_BY_TYPE/counts_VCOMB_pref.csv\n",
      "Wrote file: VERBS_BY_TYPE/counts_VCOMB_pref_nu.csv\n",
      "Wrote file: VERBS_BY_TYPE/counts_VCOMB_pref_yva.csv\n",
      "Wrote file: VERBS_BY_TYPE/counts_VCOMB_yva.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Create output directory\n",
    "output_dir = \"VERBS_BY_TYPE\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 2. und 3.: write each combi with lemmas and freqs to csv file\n",
    "for vcomb, subdict in counts.items():\n",
    "    # skip \"0\" -> that is simplex verbs \n",
    "    if vcomb == \"0\":\n",
    "        continue\n",
    "\n",
    "    # Convert Subdict (i.e. inner dictionary) to DataFrame\n",
    "    df_group = pd.DataFrame(\n",
    "        list(subdict.items()),\n",
    "        columns=[\"Lemma_norm\", \"Count\"]\n",
    "    )\n",
    "\n",
    "    # File name based on V_COMB entry \n",
    "    fname = f\"counts_VCOMB_{vcomb}.csv\"\n",
    "    path = os.path.join(output_dir, fname)\n",
    "\n",
    "    # Write to CSV\n",
    "    df_group.to_csv(path, index=False)\n",
    "    print(f\"Wrote file: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80adbe44-13fd-4405-a6a3-13e6f93c535f",
   "metadata": {},
   "source": [
    "# Create FILE with entries where \n",
    "## a. MAPPING_NONE_is_sub_of_prefix\n",
    "- expected entry:\n",
    "  NONE (=simplex verb) ['pref (=prefixed variants of simplex verb)]\n",
    "- e.g.: begati: ['pribegati', 'pobegati', 'ot_begati', 'prebegati']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "701c15fc-05a0-4b01-bfda-312478c91a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote mapping to csv: VERBS_BY_TYPE/MAPPING_NONE_is_sub_of_prefix.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Mapping of \"NONE\" and \"pref\" lemmas ---\n",
    "none_lemmas = list(counts[\"NONE\"].keys()) # e.g. [byti, rešči, iti, ...]\n",
    "pref_lemmas = list(counts[\"pref\"].keys()) # e.g. [priiti, s_tvoriti, poiti, ...]\n",
    "\n",
    "mapping = []\n",
    "for none in none_lemmas:\n",
    "    # check if none (of none_lemmas list) is substring of p (here: pref_lemma entry)\n",
    "    # e.g. none = \"iti\" is substring of p = \"poiti\" > match!\n",
    "    matches = [p for p in pref_lemmas if none in p]\n",
    "    # if match: append dictionary entry to list mapping \n",
    "    # Output: {\"NONE\": \"iti\", \"pref\": [\"poiti\", \"zaiti\", ...]}\n",
    "    mapping.append({\"NONE\": none, \"pref\": matches})\n",
    "\n",
    "# from List[Dict[str,  List[str]]] -> create dataframe df_non_pref \n",
    "df_none_pref = pd.DataFrame(mapping)\n",
    "\n",
    "# --- 2) del duplicates ---\n",
    "# a) Convert to dict\n",
    "## 1. from df > create Series where index is NONE, values is pref\n",
    "## e.g. iti [poiti, priiti]\n",
    "##      byti [pobyti]... \n",
    "# 2. convert into normal dict: i.e. { \"iti\": [\"poiti, priiti\"], \"byti\": [...], ...}\n",
    "none_to_prefs = df_none_pref.set_index(\"NONE\")[\"pref\"].to_dict()\n",
    "\n",
    "# b) Invert: collect all NONEs for each pref \n",
    "pref_to_nones = {}\n",
    "for none, prefs in none_to_prefs.items():\n",
    "    for p in prefs:\n",
    "        # {'prebyti': ['byti'], 's_byti': ['byti'], 'zabyti': ['byti'],\n",
    "        pref_to_nones.setdefault(p, []).append(none)\n",
    "\n",
    "# c) if a pref is list element of > 1 none, \n",
    "# delete the dublicate none entries, e.g.: \n",
    "## nones = [\"by\", \"byti\"] -> best_none = \"byti\"\n",
    "## BEFORE: none_to_prefs = {\"by\": [\"zabyti\"], \"byti\": [\"zabyti\"]}\n",
    "## AFTER: none_to_prefs = {\"by\": [], \"byti\": [\"zabyti\"]}\n",
    "for p, nones in pref_to_nones.items():\n",
    "    if len(nones) > 1:\n",
    "        best_none = max(nones, key=len)\n",
    "        for none in nones:\n",
    "            if none != best_none:\n",
    "                # delete p from the list of NONE\n",
    "                none_to_prefs[none] = [x for x in none_to_prefs[none] if x != p]\n",
    "\n",
    "# d) New DataFrame from cleaned dict, sorted by NONE\n",
    "df_clean = pd.DataFrame([\n",
    "    {\"NONE\": none, \"pref\": none_to_prefs[none]}\n",
    "    for none in sorted(none_to_prefs.keys())\n",
    "])\n",
    "\n",
    "# --- 3) Create output dir and save new csv file inside of it  ---\n",
    "output_dir = \"VERBS_BY_TYPE\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"MAPPING_NONE_is_sub_of_prefix.csv\")\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\"Wrote mapping to csv: {os.path.join(output_dir, \n",
    "                                           'MAPPING_NONE_is_sub_of_prefix.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1dbe9-fb32-46b0-8de3-9b6be09bfba7",
   "metadata": {},
   "source": [
    "# b.MAPPING_pref_nu_from_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee462efa-0a9b-4a95-80fa-10fce11448dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote mapping to csv: VERBS_BY_TYPE/MAPPING_nu_from_NONE.csv\n"
     ]
    }
   ],
   "source": [
    "# Define what has to be deleted in order to get the search string \n",
    "## (here: none_suffix_regex, consisting of 1 char + \"-ti\" at the end) \n",
    "## ex.: {-ati}, {-iti} etc. \n",
    "none_suffix_regex = re.compile(r'.{1}ти$')\n",
    "# Regex for PREFIX for verbs of type pref_nu\n",
    "prefix_regex = re.compile(\n",
    "    r'^(?:бе[зс]|в_?з|из_?|раз_?|рас_?|с_?|вос_?|над_?|об_?|от_?|чере[зс])'\n",
    ")\n",
    "# Regex for SUFFIX for verbs of type pref_nu\n",
    "suffix_regex = re.compile(r'нути$')\n",
    "\n",
    "# create list of all \"NONE\" lemmas \n",
    "none_raw = list(counts[\"NONE\"].keys())\n",
    "# for NONE lemmas (as keys): \n",
    "## create a list of stems (w/o stem vowel and infinitive ending) of NONE lemmas  \n",
    "## save the list as value of the corresponding key  \n",
    "none_cores = {none: none_suffix_regex.sub(\"\", none) for none in none_raw}\n",
    "\n",
    "# 2. Roh-Mapping NONE -> pref_nu (Substring-Match auf den Kern)\n",
    "# create list of all \"pref_nu\" lemmas \n",
    "pref_nu_lemmas = list(counts[\"pref_nu\"].keys())\n",
    "none_to_nus = {}\n",
    "# Iterate over the list \"none_raw\" (i.e. non-prefixex verbs)\n",
    "# (i.e. the list w/ all \"none\" lemmas, i.e [\"iti\", \"dati\",...])\n",
    "for none in none_raw:\n",
    "    core = none_cores[none]\n",
    "    matches = [p for p in pref_nu_lemmas if core in p]\n",
    "    none_to_nus[none] = matches\n",
    "\n",
    "# 3. Duplikat-Bereinigung\n",
    "# a) Invert: for each pref_nu: collect all NONE\n",
    "nu_to_nones = {}\n",
    "for none, nus in none_to_nus.items():\n",
    "    for nu in nus:\n",
    "        nu_to_nones.setdefault(nu, []).append(none)\n",
    "\n",
    "# b) In case of multiple assignments, keep the pref_nu verb\n",
    "#    only with the longest matching NONE base\n",
    "for nu, nones in nu_to_nones.items():\n",
    "    if len(nones) > 1:\n",
    "        beste_none = max(nones, key=len)\n",
    "        for none in nones:\n",
    "            if none != beste_none:\n",
    "                none_to_nus[none].remove(nu)\n",
    "\n",
    "# 4. Create and save DataFrame (sorted alphabetically by verbs of columns NONE)\n",
    "df_nu_clean = pd.DataFrame([\n",
    "    {\"NONE\": none, \"pref_nu\": none_to_nus[none]}\n",
    "    for none in sorted(none_to_nus.keys())\n",
    "])\n",
    "\n",
    "output_dir = \"VERBS_BY_TYPE\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "df_nu_clean.to_csv(\n",
    "    os.path.join(output_dir, \"MAPPING_nu_from_NONE.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"Wrote mapping to csv: {os.path.join(output_dir, 'MAPPING_nu_from_NONE.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad542b24-fa02-4750-96dd-e843f6c4a573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (OES)",
   "language": "python",
   "name": "oes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
